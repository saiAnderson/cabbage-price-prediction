{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('2000-2023高麗菜_data_file.csv')\n",
    "\n",
    "# 反轉DataFrame的順序，由上而下改為由下而上\n",
    "# original_df = original_df[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高麗菜資料總整理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新建一個DataFrame用來存儲新的資料\n",
    "new_data = []\n",
    "original_df['finaldate'] = original_df.apply(lambda row: datetime(row['year'], row['month'], row['day']), axis=1)\n",
    "\n",
    "# 計算89年1月1日至當下日期的天數，並加上專屬號碼\n",
    "start_date = datetime(2000, 1, 1)  # 89年1月1日的日期\n",
    "for index, row in original_df.iterrows():\n",
    "    current_date = row['finaldate']\n",
    "    days_difference = (current_date - start_date).days + 1\n",
    "    new_row = {\n",
    "        'dayoffset': days_difference,\n",
    "        'TransDate': row['TransDate'],\n",
    "        'Crop': row['Crop'],\n",
    "        'MarketName': row['Market'],\n",
    "        'Upper_Price': row['Upper_Price'],\n",
    "        'Middle_Price': row['Middle_Price'],\n",
    "        'Lower_Price': row['Lower_Price'],\n",
    "        'Avg_Price': row['Avg_Price'],\n",
    "        'Trans_Quantity': row['Trans_Quantity'],\n",
    "        'year': row['year'],\n",
    "        'month': row['month'],\n",
    "        'day': row['day']\n",
    "    }\n",
    "    new_data.append(new_row)\n",
    "\n",
    "# 將新的資料轉換為DataFrame\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# 將結果反轉回原始順序，由下而上改為由上而下\n",
    "# new_df = new_df[::-1].reset_index(drop=True)\n",
    "\n",
    "# 將結果寫入新的CSV檔案\n",
    "# new_df.to_csv('new_2000_2023cabbage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayoffset</th>\n",
       "      <th>TransDate</th>\n",
       "      <th>Crop</th>\n",
       "      <th>MarketName</th>\n",
       "      <th>Upper_Price</th>\n",
       "      <th>Middle_Price</th>\n",
       "      <th>Lower_Price</th>\n",
       "      <th>Avg_Price</th>\n",
       "      <th>Trans_Quantity</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>089/01/02</td>\n",
       "      <td>LA1 甘藍 初秋</td>\n",
       "      <td>109 台北一</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>192,029</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>089/01/03</td>\n",
       "      <td>LA1 甘藍 初秋</td>\n",
       "      <td>109 台北一</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>174,270</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>089/01/04</td>\n",
       "      <td>LA1 甘藍 初秋</td>\n",
       "      <td>109 台北一</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>125,426</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>089/01/05</td>\n",
       "      <td>LA1 甘藍 初秋</td>\n",
       "      <td>109 台北一</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>119,318</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>089/01/06</td>\n",
       "      <td>LA1 甘藍 初秋</td>\n",
       "      <td>109 台北一</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>118,178</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dayoffset  TransDate       Crop MarketName  Upper_Price  Middle_Price  \\\n",
       "0          2  089/01/02  LA1 甘藍 初秋    109 台北一         11.0           8.0   \n",
       "1          3  089/01/03  LA1 甘藍 初秋    109 台北一          9.0           7.0   \n",
       "2          4  089/01/04  LA1 甘藍 初秋    109 台北一          8.0           6.0   \n",
       "3          5  089/01/05  LA1 甘藍 初秋    109 台北一         10.0           7.0   \n",
       "4          6  089/01/06  LA1 甘藍 初秋    109 台北一          9.0           7.0   \n",
       "\n",
       "   Lower_Price  Avg_Price Trans_Quantity  year  month  day  \n",
       "0          5.0        8.9        192,029  2000      1    2  \n",
       "1          4.0        7.2        174,270  2000      1    3  \n",
       "2          3.0        6.7        125,426  2000      1    4  \n",
       "3          4.0        7.1        119,318  2000      1    5  \n",
       "4          5.0        6.8        118,178  2000      1    6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('new_2000_2023cabbage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7250, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 傳換天氣資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Max_10_mintes_fix_rainfall_data(df):\n",
    "    df['最大十分鐘降水量(mm)'] = df['最大十分鐘降水量(mm)'].replace('T', '0.0')\n",
    "    df['最大十分鐘降水量(mm)'] = df['最大十分鐘降水量(mm)'].replace('X', '-1')\n",
    "    df['最大十分鐘降水量(mm)'] = pd.to_numeric(df['最大十分鐘降水量(mm)'])\n",
    "    return df\n",
    "\n",
    "def Max_60_mintes_fix_rainfall_data(df):\n",
    "    df['最大六十分鐘降水量(mm)'] = df['最大六十分鐘降水量(mm)'].replace('T', '0.0')\n",
    "    df['最大六十分鐘降水量(mm)'] = df['最大六十分鐘降水量(mm)'].replace('X', '-1')\n",
    "    df['最大六十分鐘降水量(mm)'] = pd.to_numeric(df['最大六十分鐘降水量(mm)'])\n",
    "    return df\n",
    "\n",
    "def A_type_evaporation(df):\n",
    "    df['A型蒸發量(mm)'] = df['A型蒸發量(mm)'].replace('/', '-1')\n",
    "    df['A型蒸發量(mm)'] = df['A型蒸發量(mm)'].replace('X', '-1')\n",
    "    df['A型蒸發量(mm)'] = df['A型蒸發量(mm)'].replace('--', '-1')\n",
    "    df['A型蒸發量(mm)'] = pd.to_numeric(df['A型蒸發量(mm)'])\n",
    "    return df\n",
    "\n",
    "def All_sky_insolation(df):\n",
    "    df['全天空日射量(MJ/㎡)'] = df['全天空日射量(MJ/㎡)'].replace('/', '-1')\n",
    "    df['全天空日射量(MJ/㎡)'] = df['全天空日射量(MJ/㎡)'].replace('X', '-1')\n",
    "    df['全天空日射量(MJ/㎡)'] = df['全天空日射量(MJ/㎡)'].replace('--', '-1')\n",
    "    df['全天空日射量(MJ/㎡)'] = pd.to_numeric(df['全天空日射量(MJ/㎡)'])\n",
    "    return df\n",
    "\n",
    "def highest_UV_index_of_the_day(df):\n",
    "    df['日最高紫外線指數'] = df['日最高紫外線指數'].replace('/', '-1')\n",
    "    df['日最高紫外線指數'] = df['日最高紫外線指數'].replace('X', '-1')\n",
    "    df['日最高紫外線指數'] = df['日最高紫外線指數'].replace('--', '-1')\n",
    "    df['日最高紫外線指數'] = pd.to_numeric(df['日最高紫外線指數'])\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合併 yilan 全部年分資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "合併完成！\n"
     ]
    }
   ],
   "source": [
    "merged_data = pd.DataFrame()\n",
    "column_names = [\"觀測時間(day)\", \"測站氣壓(hPa)\", \"海平面氣壓(hPa)\", \"測站最高氣壓(hPa)\", \"測站最高氣壓時間(LST)\", \"測站最低氣壓(hPa)\", \"測站最低氣壓時間(LST)\", \"氣溫(℃)\", \"最高氣溫(℃)\", \"最高氣溫時間(LST)\", \"最低氣溫(℃)\", \"最低氣溫時間(LST)\", \"露點溫度(℃)\", \"相對溼度(%)\", \"最小相對溼度(%)\", \"最小相對溼度時間(LST)\", \"風速(m/s)\", \"風向(360degree)\", \"最大瞬間風(m/s)\", \"最大瞬間風風向(360degree)\", \"最大瞬間風風速時間(LST)\", \"降水量(mm)\", \"降水時數(hour)\", \"最大十分鐘降水量(mm)\", \"最大十分鐘降水量起始時間(LST)\", \"最大六十分鐘降水量(mm)\", \"最大六十分鐘降水量起始時間(LST)\", \"日照時數(hour)\", \"日照率(%)\", \"全天空日射量(MJ/㎡)\", \"能見度(km)\", \"A型蒸發量(mm)\", \"日最高紫外線指數\", \"日最高紫外線指數時間(LST)\", \"總雲量(0~10)\", \"地溫0cm\", \"地溫5cm\", \"地溫10cm\", \"地溫20cm\", \"地溫30cm\", \"地溫50cm\", \"地溫100cm\"]\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(i)\n",
    "    folder_path = r'C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\weather_data\\yilan'\n",
    "    folder_path += '\\\\'+ str(i)\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, skiprows=0, header=1)\n",
    "        df.columns = column_names\n",
    "        df = df.drop(0)\n",
    "        temp = pd.concat([merged_data, df])\n",
    "        merged_data = temp\n",
    "\n",
    "\n",
    "Max_10_mintes_fix_rainfall_data(merged_data)\n",
    "Max_60_mintes_fix_rainfall_data(merged_data)\n",
    "A_type_evaporation(merged_data)\n",
    "All_sky_insolation(merged_data)\n",
    "highest_UV_index_of_the_day(merged_data)\n",
    "merged_data.to_csv('merged_yilan_weather_data.csv', index=False)\n",
    "\n",
    "print(\"合併完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "(31, 42)\n",
      "(62, 42)\n",
      "(92, 42)\n",
      "(123, 42)\n",
      "(152, 42)\n",
      "(183, 42)\n",
      "(213, 42)\n",
      "(244, 42)\n",
      "(274, 42)\n",
      "(305, 42)\n",
      "(336, 42)\n",
      "(366, 42)\n",
      "2001\n",
      "(397, 42)\n",
      "(428, 42)\n",
      "(458, 42)\n",
      "(489, 42)\n",
      "(517, 42)\n",
      "(548, 42)\n",
      "(578, 42)\n",
      "(609, 42)\n",
      "(639, 42)\n",
      "(670, 42)\n",
      "(701, 42)\n",
      "(731, 42)\n",
      "2002\n",
      "(762, 42)\n",
      "(793, 42)\n",
      "(823, 42)\n",
      "(854, 42)\n",
      "(882, 42)\n",
      "(913, 42)\n",
      "(943, 42)\n",
      "(974, 42)\n",
      "(1004, 42)\n",
      "(1035, 42)\n",
      "(1066, 42)\n",
      "(1096, 42)\n",
      "2003\n",
      "(1127, 42)\n",
      "(1158, 42)\n",
      "(1188, 42)\n",
      "(31, 40)\n",
      "(1219, 42)\n",
      "(1247, 42)\n",
      "(1278, 42)\n",
      "(1308, 42)\n",
      "(1339, 42)\n",
      "(1369, 42)\n",
      "(1400, 42)\n",
      "(1431, 42)\n",
      "(1461, 42)\n",
      "2004\n",
      "(1492, 42)\n",
      "(1523, 42)\n",
      "(30, 40)\n",
      "(1553, 42)\n",
      "(1584, 42)\n",
      "(1613, 42)\n",
      "(1644, 42)\n",
      "(1674, 42)\n",
      "(1705, 42)\n",
      "(1735, 42)\n",
      "(1766, 42)\n",
      "(1797, 42)\n",
      "(1827, 42)\n",
      "2005\n",
      "(1858, 42)\n",
      "(1889, 42)\n",
      "(1919, 42)\n",
      "(1950, 42)\n",
      "(1978, 42)\n",
      "(2009, 42)\n",
      "(2039, 42)\n",
      "(2070, 42)\n",
      "(2100, 42)\n",
      "(2131, 42)\n",
      "(2162, 42)\n",
      "(2192, 42)\n",
      "2006\n",
      "(2223, 42)\n",
      "(2254, 42)\n",
      "(2284, 42)\n",
      "(2315, 42)\n",
      "(2343, 42)\n",
      "(2374, 42)\n",
      "(2404, 42)\n",
      "(2435, 42)\n",
      "(2465, 42)\n",
      "(2496, 42)\n",
      "(2527, 42)\n",
      "(2557, 42)\n",
      "2007\n",
      "(2588, 42)\n",
      "(2619, 42)\n",
      "(2649, 42)\n",
      "(2680, 42)\n",
      "(2708, 42)\n",
      "(2739, 42)\n",
      "(2769, 42)\n",
      "(2800, 42)\n",
      "(2830, 42)\n",
      "(2861, 42)\n",
      "(2892, 42)\n",
      "(2922, 42)\n",
      "2008\n",
      "(2953, 42)\n",
      "(2984, 42)\n",
      "(3014, 42)\n",
      "(3045, 42)\n",
      "(3074, 42)\n",
      "(3105, 42)\n",
      "(3135, 42)\n",
      "(3166, 42)\n",
      "(3196, 42)\n",
      "(3227, 42)\n",
      "(3258, 42)\n",
      "(3288, 42)\n",
      "2009\n",
      "(3319, 42)\n",
      "(3350, 42)\n",
      "(3380, 42)\n",
      "(3411, 42)\n",
      "(3439, 42)\n",
      "(3470, 42)\n",
      "(3500, 42)\n",
      "(3531, 42)\n",
      "(3561, 42)\n",
      "(3592, 42)\n",
      "(3623, 42)\n",
      "(3653, 42)\n",
      "2010\n",
      "(3684, 42)\n",
      "(3715, 42)\n",
      "(3745, 42)\n",
      "(3776, 42)\n",
      "(3804, 42)\n",
      "(3835, 42)\n",
      "(3865, 42)\n",
      "(3896, 42)\n",
      "(3926, 42)\n",
      "(3957, 42)\n",
      "(3988, 42)\n",
      "(4018, 42)\n",
      "2011\n",
      "(4049, 42)\n",
      "(4080, 42)\n",
      "(4110, 42)\n",
      "(4141, 42)\n",
      "(4169, 42)\n",
      "(4200, 42)\n",
      "(4230, 42)\n",
      "(4261, 42)\n",
      "(4291, 42)\n",
      "(4322, 42)\n",
      "(4353, 42)\n",
      "(4383, 42)\n",
      "2012\n",
      "(4414, 42)\n",
      "(4445, 42)\n",
      "(4475, 42)\n",
      "(4506, 42)\n",
      "(4535, 42)\n",
      "(4566, 42)\n",
      "(4596, 42)\n",
      "(4627, 42)\n",
      "(4657, 42)\n",
      "(4688, 42)\n",
      "(4719, 42)\n",
      "(4749, 42)\n",
      "2013\n",
      "(4780, 42)\n",
      "(4811, 42)\n",
      "(4841, 42)\n",
      "(4872, 42)\n",
      "(4900, 42)\n",
      "(4931, 42)\n",
      "(4961, 42)\n",
      "(4992, 42)\n",
      "(5022, 42)\n",
      "(5053, 42)\n",
      "(5084, 42)\n",
      "(5114, 42)\n",
      "2014\n",
      "(31, 40)\n",
      "(5145, 42)\n",
      "(31, 40)\n",
      "(5176, 42)\n",
      "(5206, 42)\n",
      "(5237, 42)\n",
      "(5265, 42)\n",
      "(5296, 42)\n",
      "(5326, 42)\n",
      "(5357, 42)\n",
      "(5387, 42)\n",
      "(5418, 42)\n",
      "(5449, 42)\n",
      "(5479, 42)\n",
      "2015\n",
      "(5510, 42)\n",
      "(5541, 42)\n",
      "(5571, 42)\n",
      "(5602, 42)\n",
      "(5630, 42)\n",
      "(5661, 42)\n",
      "(5691, 42)\n",
      "(5722, 42)\n",
      "(5752, 42)\n",
      "(5783, 42)\n",
      "(5814, 42)\n",
      "(5844, 42)\n",
      "2016\n",
      "(5875, 42)\n",
      "(5906, 42)\n",
      "(5936, 42)\n",
      "(5967, 42)\n",
      "(5996, 42)\n",
      "(6027, 42)\n",
      "(6057, 42)\n",
      "(6088, 42)\n",
      "(6118, 42)\n",
      "(6149, 42)\n",
      "(6180, 42)\n",
      "(6210, 42)\n",
      "2017\n",
      "(6241, 42)\n",
      "(6272, 42)\n",
      "(6302, 42)\n",
      "(6333, 42)\n",
      "(6361, 42)\n",
      "(6392, 42)\n",
      "(6422, 42)\n",
      "(6453, 42)\n",
      "(6483, 42)\n",
      "(6514, 42)\n",
      "(6545, 42)\n",
      "(6575, 42)\n",
      "2018\n",
      "(6606, 42)\n",
      "(6637, 42)\n",
      "(6667, 42)\n",
      "(6698, 42)\n",
      "(6726, 42)\n",
      "(6757, 42)\n",
      "(6787, 42)\n",
      "(6818, 42)\n",
      "(6848, 42)\n",
      "(6879, 42)\n",
      "(6910, 42)\n",
      "(6940, 42)\n",
      "2019\n",
      "(6971, 42)\n",
      "(7002, 42)\n",
      "(30, 40)\n",
      "(7032, 42)\n",
      "(7062, 42)\n",
      "(7090, 42)\n",
      "(7121, 42)\n",
      "(7151, 42)\n",
      "(7182, 42)\n",
      "(7212, 42)\n",
      "(7243, 42)\n",
      "(7274, 42)\n",
      "(7304, 42)\n",
      "2020\n",
      "(7335, 42)\n",
      "(7366, 42)\n",
      "(7396, 42)\n",
      "(7427, 42)\n",
      "(7456, 42)\n",
      "(7487, 42)\n",
      "(7517, 42)\n",
      "(7548, 42)\n",
      "(7578, 42)\n",
      "(7609, 42)\n",
      "(7640, 42)\n",
      "(7670, 42)\n",
      "2021\n",
      "(7701, 42)\n",
      "(7732, 42)\n",
      "(7762, 42)\n",
      "(7793, 42)\n",
      "(7821, 42)\n",
      "(7852, 42)\n",
      "(7882, 42)\n",
      "(7913, 42)\n",
      "(7943, 42)\n",
      "(7974, 42)\n",
      "(8005, 42)\n",
      "(8035, 42)\n",
      "2022\n",
      "(8066, 42)\n",
      "(8097, 42)\n",
      "(8127, 42)\n",
      "(8158, 42)\n",
      "(8186, 42)\n",
      "(8217, 42)\n",
      "(8247, 42)\n",
      "(8278, 42)\n",
      "(8308, 42)\n",
      "(8339, 42)\n",
      "(8370, 42)\n",
      "(8399, 42)\n",
      "2023\n",
      "(8430, 42)\n",
      "(8461, 42)\n",
      "(8491, 42)\n",
      "(8522, 42)\n",
      "(8550, 42)\n",
      "(8581, 42)\n",
      "(8611, 42)\n",
      "(8642, 42)\n",
      "(8672, 42)\n",
      "(8703, 42)\n",
      "(8734, 42)\n",
      "(8764, 42)\n",
      "合併完成！\n"
     ]
    }
   ],
   "source": [
    "# chiayi\n",
    "merged_data = pd.DataFrame()\n",
    "column_names = [\"觀測時間(day)\", \"測站氣壓(hPa)\", \"海平面氣壓(hPa)\", \"測站最高氣壓(hPa)\", \"測站最高氣壓時間(LST)\", \"測站最低氣壓(hPa)\", \"測站最低氣壓時間(LST)\", \"氣溫(℃)\", \"最高氣溫(℃)\", \"最高氣溫時間(LST)\", \"最低氣溫(℃)\", \"最低氣溫時間(LST)\", \"露點溫度(℃)\", \"相對溼度(%)\", \"最小相對溼度(%)\", \"最小相對溼度時間(LST)\", \"風速(m/s)\", \"風向(360degree)\", \"最大瞬間風(m/s)\", \"最大瞬間風風向(360degree)\", \"最大瞬間風風速時間(LST)\", \"降水量(mm)\", \"降水時數(hour)\", \"最大十分鐘降水量(mm)\", \"最大十分鐘降水量起始時間(LST)\", \"最大六十分鐘降水量(mm)\", \"最大六十分鐘降水量起始時間(LST)\", \"日照時數(hour)\", \"日照率(%)\", \"全天空日射量(MJ/㎡)\", \"能見度(km)\", \"A型蒸發量(mm)\", \"日最高紫外線指數\", \"日最高紫外線指數時間(LST)\", \"總雲量(0~10)\", \"地溫0cm\", \"地溫5cm\", \"地溫10cm\", \"地溫20cm\", \"地溫30cm\", \"地溫50cm\", \"地溫100cm\"]\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(i)\n",
    "    folder_path = r'C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\weather_data\\chiayi'\n",
    "    folder_path += '\\\\'+ str(i)\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, skiprows=0, header=1)\n",
    "        if(df.columns.size != 42):\n",
    "            df = df.drop(0)\n",
    "            print(df.shape)\n",
    "            temp = pd.concat([merged_data, df] ,join='outer')\n",
    "            merged_data = temp\n",
    "            print(merged_data.shape)\n",
    "        else:\n",
    "            df.columns = column_names\n",
    "            df = df.drop(0)\n",
    "            merged_data = pd.concat([merged_data, df])\n",
    "            print(merged_data.shape)\n",
    "            \n",
    "Max_10_mintes_fix_rainfall_data(merged_data)\n",
    "Max_60_mintes_fix_rainfall_data(merged_data)\n",
    "A_type_evaporation(merged_data)\n",
    "All_sky_insolation(merged_data)\n",
    "highest_UV_index_of_the_day(merged_data)\n",
    "merged_data.to_csv('merged_yilan_weather_data.csv', index=False)\n",
    "\n",
    "print(\"合併完成！\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "合併完成！\n"
     ]
    }
   ],
   "source": [
    "# nantou\n",
    "merged_data = pd.DataFrame()\n",
    "column_names = [\"觀測時間(day)\", \"測站氣壓(hPa)\", \"海平面氣壓(hPa)\", \"測站最高氣壓(hPa)\", \"測站最高氣壓時間(LST)\", \"測站最低氣壓(hPa)\", \"測站最低氣壓時間(LST)\", \"氣溫(℃)\", \"最高氣溫(℃)\", \"最高氣溫時間(LST)\", \"最低氣溫(℃)\", \"最低氣溫時間(LST)\", \"露點溫度(℃)\", \"相對溼度(%)\", \"最小相對溼度(%)\", \"最小相對溼度時間(LST)\", \"風速(m/s)\", \"風向(360degree)\", \"最大瞬間風(m/s)\", \"最大瞬間風風向(360degree)\", \"最大瞬間風風速時間(LST)\", \"降水量(mm)\", \"降水時數(hour)\", \"最大十分鐘降水量(mm)\", \"最大十分鐘降水量起始時間(LST)\", \"最大六十分鐘降水量(mm)\", \"最大六十分鐘降水量起始時間(LST)\", \"日照時數(hour)\", \"日照率(%)\", \"全天空日射量(MJ/㎡)\", \"能見度(km)\", \"A型蒸發量(mm)\", \"日最高紫外線指數\", \"日最高紫外線指數時間(LST)\", \"總雲量(0~10)\", \"地溫0cm\", \"地溫5cm\", \"地溫10cm\", \"地溫20cm\", \"地溫30cm\", \"地溫50cm\", \"地溫100cm\"]\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(i)\n",
    "    folder_path = r'C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\weather_data\\nantou'\n",
    "    folder_path += '\\\\'+ str(i)\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, skiprows=0, header=1)\n",
    "        if(df.columns.size != 42):\n",
    "            df = df.drop(0)\n",
    "            temp = pd.concat([merged_data, df] ,join='outer')\n",
    "            merged_data = temp\n",
    "        else:\n",
    "            df.columns = column_names\n",
    "            df = df.drop(0)\n",
    "            merged_data = pd.concat([merged_data, df])\n",
    "            \n",
    "Max_10_mintes_fix_rainfall_data(merged_data)\n",
    "Max_60_mintes_fix_rainfall_data(merged_data)\n",
    "A_type_evaporation(merged_data)\n",
    "All_sky_insolation(merged_data)\n",
    "highest_UV_index_of_the_day(merged_data)\n",
    "merged_data.to_csv('merged_yilan_weather_data.csv', index=False)\n",
    "\n",
    "print(\"合併完成！\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n",
      "合併完成！\n"
     ]
    }
   ],
   "source": [
    "# taichung\n",
    "merged_data = pd.DataFrame()\n",
    "column_names = [\"觀測時間(day)\", \"測站氣壓(hPa)\", \"海平面氣壓(hPa)\", \"測站最高氣壓(hPa)\", \"測站最高氣壓時間(LST)\", \"測站最低氣壓(hPa)\", \"測站最低氣壓時間(LST)\", \"氣溫(℃)\", \"最高氣溫(℃)\", \"最高氣溫時間(LST)\", \"最低氣溫(℃)\", \"最低氣溫時間(LST)\", \"露點溫度(℃)\", \"相對溼度(%)\", \"最小相對溼度(%)\", \"最小相對溼度時間(LST)\", \"風速(m/s)\", \"風向(360degree)\", \"最大瞬間風(m/s)\", \"最大瞬間風風向(360degree)\", \"最大瞬間風風速時間(LST)\", \"降水量(mm)\", \"降水時數(hour)\", \"最大十分鐘降水量(mm)\", \"最大十分鐘降水量起始時間(LST)\", \"最大六十分鐘降水量(mm)\", \"最大六十分鐘降水量起始時間(LST)\", \"日照時數(hour)\", \"日照率(%)\", \"全天空日射量(MJ/㎡)\", \"能見度(km)\", \"A型蒸發量(mm)\", \"日最高紫外線指數\", \"日最高紫外線指數時間(LST)\", \"總雲量(0~10)\", \"地溫0cm\", \"地溫5cm\", \"地溫10cm\", \"地溫20cm\", \"地溫30cm\", \"地溫50cm\", \"地溫100cm\"]\n",
    "\n",
    "for i in range(2000,2024):\n",
    "    print(i)\n",
    "    folder_path = r'C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\weather_data\\taichung'\n",
    "    folder_path += '\\\\'+ str(i)\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, skiprows=0, header=1)\n",
    "        if(df.columns.size != 42):\n",
    "            df = df.drop(0)\n",
    "            temp = pd.concat([merged_data, df] ,join='outer')\n",
    "            merged_data = temp\n",
    "        else:\n",
    "            df.columns = column_names\n",
    "            df = df.drop(0)\n",
    "            merged_data = pd.concat([merged_data, df])\n",
    "\n",
    "Max_10_mintes_fix_rainfall_data(merged_data)\n",
    "Max_60_mintes_fix_rainfall_data(merged_data)\n",
    "A_type_evaporation(merged_data)\n",
    "All_sky_insolation(merged_data)\n",
    "highest_UV_index_of_the_day(merged_data)\n",
    "merged_data.to_csv('merged_yilan_weather_data.csv', index=False)\n",
    "\n",
    "print(\"合併完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8764, 42)\n",
      "(8766, 43)\n",
      "(8765, 42)\n",
      "(8749, 42)\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\蔡昇翰\\merged_chiayi_weather_data.csv\")\n",
    "df2 = pd.read_csv(r\"C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\蔡昇翰\\merged_nantou_weather_data.csv\")\n",
    "df3 = pd.read_csv(r\"C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\蔡昇翰\\merged_taichung_weather_data.csv\")\n",
    "df4 = pd.read_csv(r\"C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\蔡昇翰\\merged_yilan_weather_data.csv\")\n",
    "\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "print(df3.shape)\n",
    "print(df4.shape)\n",
    "\n",
    "nan_count_per_column1 = df1['測站最高氣壓時間(LST)'].isna().sum()\n",
    "nan_count_per_column2 = df2['測站最高氣壓時間(LST)'].isna().sum()\n",
    "nan_count_per_column3 = df3['測站最高氣壓時間(LST)'].isna().sum()\n",
    "nan_count_per_column4 = df4['測站最高氣壓時間(LST)'].isna().sum()\n",
    "print(nan_count_per_column1)\n",
    "print(nan_count_per_column2)\n",
    "print(nan_count_per_column3)\n",
    "print(nan_count_per_column4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加缺失值標記以及對於2016/1/1的日期差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       367.0\n",
      "1       368.0\n",
      "2       369.0\n",
      "3       370.0\n",
      "4       371.0\n",
      "        ...  \n",
      "2246      NaN\n",
      "2247      NaN\n",
      "2248      NaN\n",
      "2249      NaN\n",
      "2250      NaN\n",
      "Name: dayoffset, Length: 2251, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('merged_data.csv')\n",
    "\n",
    "df['測站最高氣壓時間(LST)'] = pd.to_datetime(df['測站最高氣壓時間(LST)'], format='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "# 計算日期與基準日期（2016/01/01）之間的差異，並新增一個 \"日期\" 欄位\n",
    "base_date = pd.to_datetime('2000/01/01', format='%Y/%m/%d')\n",
    "df['dayoffset'] = (df['測站最高氣壓時間(LST)'] - base_date).dt.days+1\n",
    "df = pd.concat([df['dayoffset'], df.drop(columns=['dayoffset'])], axis=1)\n",
    "# 顯示處理後的 DataFrame\n",
    "# 將處理後的 DataFrame 寫入新的 CSV 檔案\n",
    "df.to_csv('merged_data.csv', index=False)\n",
    "print(df['dayoffset'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均處理跳過缺失值的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "8759    8670\n",
      "8760    8671\n",
      "8761    8672\n",
      "8762    8673\n",
      "8763    8674\n",
      "Name: dayoffset, Length: 8764, dtype: int64\n",
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "8761    8670\n",
      "8762    8671\n",
      "8763    8672\n",
      "8764    8673\n",
      "8765    8674\n",
      "Name: dayoffset, Length: 8766, dtype: int64\n",
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "8760    8670\n",
      "8761    8671\n",
      "8762    8672\n",
      "8763    8673\n",
      "8764    8674\n",
      "Name: dayoffset, Length: 8765, dtype: int64\n",
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "8760    8670\n",
      "8761    8671\n",
      "8762    8672\n",
      "8763    8673\n",
      "8764    8674\n",
      "Name: dayoffset, Length: 8765, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "a = ['chiayi','nantou','taichung','yilan']\n",
    "for i in a:\n",
    "    addr = r\"C:\\Users\\user\\OneDrive\\桌面\\GitHub\\Big-Data-project\\蔡昇翰\\merged_\"+ i +\"_weather_data.csv\"\n",
    "    df = pd.read_csv(addr)\n",
    "\n",
    "    df['測站最高氣壓時間(LST)'] = pd.to_datetime(df['測站最高氣壓時間(LST)'], format='%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "    # 計算日期與基準日期（2016/01/01）之間的差異，並新增一個 \"日期\" 欄位\n",
    "    base_date = pd.to_datetime('2000/01/01', format='%Y/%m/%d')\n",
    "    df['dayoffset'] = (df['測站最高氣壓時間(LST)'] - base_date).dt.days+1\n",
    "    df = pd.concat([df['dayoffset'], df.drop(columns=['dayoffset'])], axis=1)\n",
    "    # 顯示處理後的 DataFrame\n",
    "    # 將處理後的 DataFrame 寫入新的 CSV 檔案\n",
    "    path = 'ALL_'+ i + '_merged_data.csv'\n",
    "    df.to_csv(path , index=False)\n",
    "    print(df['dayoffset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:72: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:89: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:106: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data = float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:125: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  temp_sum = temp_sum+float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:72: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:89: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:106: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data = float(data)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15484\\538959614.py:125: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  data=float(data)\n"
     ]
    }
   ],
   "source": [
    "features=[\"測站氣壓(hPa)\",\"海平面氣壓(hPa)\",\"測站最高氣壓(hPa)\",\"測站最低氣壓(hPa)\",\"氣溫(℃)\",\"最高氣溫(℃)\",\"最低氣溫(℃)\",\"露點溫度(℃)\",\"相對溼度(%)\",\"最小相對溼度(%)\",\"風速(m/s)\",\"風向(360degree)\",\"最大瞬間風(m/s)\",\"最大瞬間風風向(360degree)\",\"降水量(mm)\",\"降水時數(hour)\",\"最大十分鐘降水量(mm)\",\"最大六十分鐘降水量(mm)\",\"日照時數(hour)\",\"全天空日射量(MJ/㎡)\",\"能見度(km)\",\"A型蒸發量(mm)\",\"日最高紫外線指數\",\"總雲量(0~10)\",\"地溫0cm\",\"地溫5cm\",\"地溫10cm\",\"地溫20cm\",\"地溫30cm\",\"地溫50cm\",\"地溫100cm\"]\n",
    "new_features = [f'{feature}_avg' for feature in features]\n",
    "pre_features=[\"Trans_Quantity_day1\",\"Trans_Quantity_day2\",\"Trans_Quantity_day3\",\"Trans_Quantity_day4\",\"Trans_Quantity_day5\",\"Avg_Price_day1\",\"Avg_Price_day2\",\"Avg_Price_day3\",\"Avg_Price_day4\",\"Avg_Price_day5\"]\n",
    "# Avg_Price\n",
    "# Trans_Quantity\n",
    "\n",
    "# 迴圈處理每個檔案\n",
    "\n",
    "\n",
    "# 讀取 CSV 檔案\n",
    "df = pd.read_csv('merged_weather_data.csv')\n",
    "\n",
    "dest = pd.read_csv('new_cabbage.csv')\n",
    "for day in range(548,2558):##2558 733\n",
    "    target_row =  dest[dest['dayoffset'] == day]\n",
    "    index=target_row.index\n",
    "    if target_row.empty:\n",
    "        continue\n",
    "    # 初始化每個檔案的溫度總和和有效數據個數\n",
    "    selected_data = pd.Series([])\n",
    "    for i in range(5):\n",
    "        selected_data = pd.concat([selected_data, dest.loc[index - 5 + i, 'Trans_Quantity']])\n",
    "    for i in range(5):\n",
    "        selected_data = pd.concat([selected_data, dest.loc[index - 5 + i, 'Avg_Price']])\n",
    "    dest.loc[dest['dayoffset'] == day, pre_features] = selected_data.values\n",
    "    dest.loc[dest['dayoffset'] == day, features] = df.loc[df['dayoffset'] == day, features].values\n",
    "for day in range (0,548):#548\n",
    "    target_row = dest[dest['dayoffset'] == day]\n",
    "    if target_row.empty:\n",
    "        continue\n",
    "    dest = dest.drop(dest[dest['dayoffset'] == day].index)\n",
    "##填原本的值回去\n",
    "\n",
    "##再來是平均後的值\n",
    "for day in range(548,2558):##2558 733\n",
    "    target_row = dest[dest['dayoffset'] == day]\n",
    "    if target_row.empty:\n",
    "        continue\n",
    "    # 初始化每個檔案的溫度總和和有效數據個數\n",
    "    for temp, new_feature in zip(features, new_features):\n",
    "        temp_sum = 0\n",
    "        cnt=0\n",
    "        valid_count = 0\n",
    "        \n",
    "        # average 60 days\n",
    "        for num in range (day-60,day):\n",
    "            goal_row = df[df['dayoffset'] == num]\n",
    "            if goal_row.empty:\n",
    "                continue\n",
    "            # 檢查是否為有效數據\n",
    "            data=goal_row[temp]\n",
    "            if not data.isin([\"--\", \"T\", \"X\", \"/\"]).all():\n",
    "                temp_sum = temp_sum+float(data)\n",
    "                valid_count = valid_count + 1\n",
    "        if valid_count==0:\n",
    "            avg=0\n",
    "        else:\n",
    "            avg=temp_sum/valid_count\n",
    "        dest.loc[dest['dayoffset'] == day,new_feature] = avg\n",
    "\n",
    "        # find 3 days average tempature \"highest\" and \"lowest\"\n",
    "        if(temp == \"氣溫(℃)\"):\n",
    "            #  3 highest tempature  \n",
    "            max3 = [-1,-1,-1]\n",
    "            for num in range(day-60,day):\n",
    "                goal_row = df[df['dayoffset'] == num]\n",
    "                if goal_row.empty:\n",
    "                    continue\n",
    "\n",
    "                data=goal_row[temp]\n",
    "                if not data.isin([\"--\", \"T\", \"X\", \"/\"]).all():\n",
    "                    data=float(data)\n",
    "                    min_tempature = min(max3)\n",
    "                    if(data > min_tempature):\n",
    "                        max3 = [data if x == min_tempature else x for x in max3]\n",
    "            # add feature\n",
    "            max3_average = sum(max3)/3\n",
    "            dest.loc[dest['dayoffset']== day,\"3highest_temp_avg\"] = max3_average\n",
    "                \n",
    "            # 3 lowest tempature \n",
    "            min3 = [100,100,100]\n",
    "            for num in range(day-60,day):\n",
    "                goal_row = df[df['dayoffset'] == num]\n",
    "                if goal_row.empty:\n",
    "                    continue\n",
    "\n",
    "                data=goal_row[temp]\n",
    "                if not data.isin([\"--\", \"T\", \"X\", \"/\"]).all():\n",
    "                    data=float(data)\n",
    "                    max_tempature = max(min3)\n",
    "                    if(data < max_tempature):\n",
    "                        min3 = [data if x == max_tempature else x for x in min3]\n",
    "            # add feature \n",
    "            min3_average = sum(min3)/3\n",
    "            dest.loc[dest['dayoffset']== day,\"3lowest_temp_avg\"] = min3_average\n",
    "\n",
    "            # days higher than 22 degree and lower than 13\n",
    "            higher_num = 0\n",
    "            lower_num = 0 \n",
    "            for num in range(day-60,day):\n",
    "                goal_row = df[df['dayoffset'] == num]\n",
    "                if goal_row.empty:\n",
    "                    continue\n",
    "                data=goal_row[temp]\n",
    "                if not data.isin([\"--\", \"T\", \"X\", \"/\"]).all():\n",
    "                    data = float(data)\n",
    "                    if(data > 22):\n",
    "                        higher_num = higher_num + 1\n",
    "                    if(data < 13):\n",
    "                        lower_num = lower_num + 1\n",
    "\n",
    "            dest.loc[dest['dayoffset']== day,\"TmpHigher22_num\"] = higher_num\n",
    "            dest.loc[dest['dayoffset']== day,\"TmpLower13_num\"] = lower_num\n",
    "        \n",
    "        if(temp == \"降水量(mm)\"):\n",
    "            #  3 highest rain fall  \n",
    "            max3 = [-1,-1,-1]\n",
    "            for num in range(day-60,day):\n",
    "                goal_row = df[df['dayoffset'] == num]\n",
    "                if goal_row.empty:\n",
    "                    continue\n",
    "\n",
    "                data=goal_row[temp]\n",
    "                if not data.isin([\"--\", \"T\", \"X\", \"/\"]).all():\n",
    "                    data=float(data)\n",
    "                    min_rainfall = min(max3)\n",
    "                    if(data > min_rainfall):\n",
    "                        max3 = [data if x == min_rainfall else x for x in max3]\n",
    "            # add feature\n",
    "            max3_average = sum(max3)/3\n",
    "            dest.loc[dest['dayoffset']== day,\"3highest_RainFall_avg\"] = max3_average\n",
    "\n",
    "\n",
    "\n",
    "dest.to_csv('New_final_training_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
